---
title: "HOMEWORK 2 - Creating Value Through Data Mining (S402010)"
author: "Liam Phan"
date: "`r Sys.Date()`"
output:
  rmdformats::material :
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: true
    highlight: tango
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
rm(list = ls()) # clean environment
cat("\014") # clean console
```

# <span style="color: #1c6155;">Quick Start</span> 

## Loading Packages

```{r 1, warning=FALSE, message=FALSE}

library(data.table) # Efficient Dataframe 
library(lubridate) # For Dates 
library(tidyverse) # Multiple Package for Useful Data wrangling
library(esquisse) # Intuitive plotting
library(plyr) # Data splitting
library(dplyr)
library(ggplot2) # Plot Graphs
library(naniar) # for NA exploration in Dataframe
library(plotly) # Make ggplot2 Dynamic
library(DT) # Render Table in a explorable UI
library(gridExtra) # Multiple Plot at once
library(corrplot) # Correlation Plot
library(RColorBrewer) # For Color Palette
library(rmdformats) # Theme of HTML
library(manipulateWidget) # Handling multiple plotly graphs
library(flextable) # Show Table
library(class) # K-NN

```

> Those are required packages

# <span style="color: #1c6155;">Exercise 1.</span> 

## 5.6 Evaluating Predictive Performance

### a. 

> If the company beings working with a new set of 1000 leads to sell the same services, similar to the 500 in the plot study, witout any use of predictive modeling to target sales efforts, what is the estimated profit? 

<br />

Without any predictive modeling, we can roughly estimated the profit with the following formula: 

$$ Sales_{Estimated} = 1000*\$2128 = \$2128000  $$

<br />

But the company will also have expenditures related to their sales, which would negatively impact the Total Profit. The sales effort would be:

$$ Costs_{Estimated} = 1000*\$2500 = \$2500000   $$

<br />

Leading to negative Total Profit of... 

$$ TotalProfit_{Estimated} = Sales_{Estimated} - Costs_{Estimated} \\ = \$2128000 - \$2500000 = - \$372000  $$

<br />

### b.

> If the firm wants the average profit on each sale to at least double the sales effort cost, and applies an appopriate cutoff with this predictive model to a new set of 1000 leads, how far down the new list of 1000 should it proceed (how many deciles)?

If we want to double the average profit on each sale, we should take the first decile (10%) on the Decile-wise lift chart which double the mean. 

$$ Ratio_{Estimated} = \dfrac{2*\$2500}{\$2128} = 2.35 $$

<br />

### c.

> Still considering the new list of 1000 leads, if the company applies this predictive model with a lower cutoff of $2500, how far should it proceed down the ranked leads, in terms of deciles?

We want the cutoff to be $2500: 

$$ Ratio_{Estimated} = \dfrac{\$2500}{\$2128} = 1.17 $$

If we take a look at the Decile-wise lift chart, we see that the 6th decile (approx mean-reponse of 1, same as 2128$)

<br />

### d. 

> Why use this two-stage process for predicting sales--why not simply develop a model for predicting profit for the 1000 new leads?

# <span style="color: #1c6155;">Exercise 2.</span> 

## 7.2 Personnal Loan Acceptance

### Loading Dataset and Basic Data Quality Check

Dimensions, Variables Count and Dataset Structure

```{r 2, echo=FALSE, warning=FALSE}

UniversalBank1 <- fread("DATA/UniversalBank.csv")

flextable(head(UniversalBank1)) %>% 
  fontsize(size = 7, part = "all")

dim(UniversalBank1)

sapply(UniversalBank1, function(x) length(unique(x)))

str(UniversalBank1)


```

<center>

Missing Variables Plot

```{r 3,echo=FALSE,warning=FALSE}

gg_miss_var(UniversalBank1, show_pct = TRUE)

```

No Missing Values

</center>

### Partition The Data Into Training (60%) and Validation (40%) Sets

```{r 4,echo=TRUE}

# Setting Seed
set.seed(1)

# Splitting Training and Validation 
sample <- sample(c(TRUE, FALSE), nrow(UniversalBank1), replace=TRUE, prob=c(0.6,0.4))
training  <- UniversalBank1[sample, ]
validation   <- UniversalBank1[!sample, ]

# Checking if proportions are right
train_prop <- dim(training)
validation_prop <- dim(validation)

train_prop_100 <- (train_prop[1]/nrow(UniversalBank1))*100
validation_prop_100 <- (validation_prop[1]/nrow(UniversalBank1))*100

paste(train_prop_100,"% In Training",validation_prop_100,"% In Validation")

``` 

### a. Considering the following customer: 

> Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. 

Perform a Κ-NN Classification with all predictors except ID and ZIP code using Κ = 1 

```{r 5, echo=TRUE, results='hide'}

# Setting Seed
set.seed(1)

# Removing Some Predictors
training <- training[,-c("ID","ZIP Code")]
validation <- validation[,-c("ID","ZIP Code")]

# Target Variable As Factor
training$`Personal Loan` <- as.factor(training$`Personal Loan`) 
validation$`Personal Loan` <- as.factor(validation$`Personal Loan`) 

# Education As Factor
training$Education <- as.factor(training$Education) 
validation$Education <- as.factor(validation$Education) 

# Education One-Hot Encoding
Education_As_Dummy_Training <- model.matrix(~0+training$Education)
Education_As_Dummy_Validation <- model.matrix(~0+validation$Education)

# Append to Training and Validation Sets
training <- cbind(training,Education_As_Dummy_Training)
training <- training[,-c("Education")]

validation <- cbind(validation,Education_As_Dummy_Validation)
validation <- validation[,-c("Education")]

# Renaming Education
training = training %>% rename( Education_1 = `training$Education1` , Education_2 = `training$Education2`, Education_3 = `training$Education3`)
validation = validation %>% rename( Education_1 = `validation$Education1` , Education_2 = `validation$Education2`, Education_3 = `validation$Education3`)

# Preprocess for Data Normalization
library(caret)

training_norm <- training
validation_norm <- validation

training_norm_s <- training[,-c("Personal Loan")]

norm_values <- preProcess(training_norm_s,method = c("center","scale"))

training_norm <- predict(norm_values,training)
validation_norm <- predict(norm_values,validation)

# KNN Model using class package
library(class)

# Data frame for a specific customer not in Data
Customer_Test <- data.frame("Age"=40,"Experience"=10,"Income"=84,"Family"=2,"CCAvg"=2,"Mortgage"=0,"Securities Account"=0,"CD Account"=0,"Online"=1,"CreditCard"=1,"Education_1"=0,"Education_2"=1,"Education_3"=0, check.names=FALSE)

# Preprocess the Customer New Data
Customer_Test_norm <- predict(norm_values, Customer_Test)

## KNN Training for Customer
predictions_customer <- knn(train=training_norm[,-c("Personal Loan")],test = Customer_Test_norm, cl = training_norm$`Personal Loan`, k=1)

predictions_customer <- as.factor(predictions_customer)

levels(predictions_customer) <- c("Fail","Success")

# Append Predictions to Customer not in Data
Customer_Test$Predicted <- predictions_customer

# Correct Factors of previous Validation
levels(Customer_Test$Predicted) <- c("Fail","Success")

```

<center>

```{r 6, echo=TRUE}

# Table Customer after Predictions
flextable(head(Customer_Test)) %>% 
  fontsize(size = 7, part = "all")

```

</center>

> This Customer would be classified as not getting a Personnal Loan (Fail)

### b. What is the Choice of Κ that balances between overfitting and ignoring the predictor information?

<center>

```{r 7, echo=TRUE}

# Setting Seed
set.seed(1)

# Load Caret 
library(caret)

# Number of iterations
max_iterations = 20

# Dataframe with 2 columns: k and accuracy
accuracy.df <- data.frame(k=seq(1,iterations,1),accuracy=rep(0,iterations))

# Compute K-NN for different k on validation
for(i in 1:max_iterations){
  # Testing K-NN
  knn.prediction <- knn(train = training_norm[,-c("Personal Loan")], test=validation_norm[,-c("Personal Loan")] , cl=training_norm$`Personal Loan`, k=i)
  # Storing into the accuracy.df results
  accuracy.df[i,2] <- confusionMatrix(knn.prediction, validation$`Personal Loan`)$overall[1]
}

# Table of Accuracy
flextable(accuracy.df) %>% 
  fontsize(size = 12, part = "all")

# Ploting the K and accuracy together
ggplot(accuracy.df) +
 aes(x = k, y = accuracy) +
 geom_line(size = 0.5, colour = "#112446") +
 labs(x = "Number of K", 
 y = "Accuracy (Between Training and Validation)", title = "K-NN Accuracy regarding parameter K") +
 theme_minimal()

# Choosing Efficient K
highest_K <- which.max(accuracy.df$accuracy)

print(paste("Best K for Highest Accuracy is",highest_K))

```

</center>

### c. Show the confusion matrix for the validation data that results from using best Κ

<center>

```{r 8, echo=TRUE}

# Setting Seed
set.seed(1)

# Computing Confusion Matrix with Best K
predictions_k <- knn(train=training_norm[,-c("Personal Loan")],test = validation_norm[,-c("Personal Loan")], cl = training_norm$`Personal Loan`, highest_K)

# As Factor Predictions
predictions_k <- as.factor(predictions_k)

# Relabel 0 and 1 to "Success" and "Fail
levels(predictions_k)<- c("Fail","Success")
levels(validation$`Personal Loan`) <- c("Fail","Success")

# Confusion Matrix
Confusion_Matrix_k <- confusionMatrix(data = predictions_k, reference = validation$`Personal Loan`)

# Plot
draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#1c6155')
  text(195, 435, 'Fail', cex=1.2)
  rect(250, 430, 340, 370, col='#77baae')
  text(295, 435, 'Success', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#77baae')
  rect(250, 305, 340, 365, col='#1c6155')
  text(140, 400, 'Fail', cex=1.2, srt=90)
  text(140, 335, 'Succes', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  


#Plot the Confusion Matrix
draw_confusion_matrix(Confusion_Matrix_k)

```

</center>

### d. Consider the following customer:

> Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. 

```{r 9, echo=TRUE}

# Setting Seed
set.seed(1)

# KNN Model on a specific customer not in Data
Customer_Test_2 <- data.frame("Age"=40,"Experience"=10,"Income"=84,"Family"=2,"CCAvg"=2,"Mortgage"=0,"Securities Account"=0,"CD Account"=0,"Online"=1,"CreditCard"=1,"Education_1"=0,"Education_2"=1,"Education_3"=0, check.names=FALSE)

# Preprocess the Customer New Data
Customer_Test_2_norm <- predict(norm_values, Customer_Test_2)

## KNN Training for Customer
predictions_customer_2 <- knn(train=training_norm[,-c("Personal Loan")],test = Customer_Test_2_norm, cl = training_norm$`Personal Loan`, k=highest_K)

predictions_customer_2 <- as.factor(predictions_customer_2)
levels(predictions_customer_2) <- c("Fail","Succes")

# Append Predictions to Customer not in Data
Customer_Test_2$Predicted <- predictions_customer_2

```

```{r 10, echo=TRUE}

# Table Customer after Predictions
flextable(head(Customer_Test_2)) %>% 
  fontsize(size = 7, part = "all")

```

### e. Repartition the data (50%-30%-20%)

```{r 11, echo=TRUE}

# Setting Seed
set.seed(1)

# Splitting Training and Validation and Test
splitting <- sample(1:3,size=nrow(UniversalBank1),replace=TRUE,prob=c(0.5,0.3,0.2))
train <- UniversalBank1[splitting==1,]
valid <- UniversalBank1[splitting==2,]
test <- UniversalBank1[splitting==3,]

# Checking if proportions are right
Prop_train <- (nrow(train)/nrow(UniversalBank1))*100
Prop_valid <- (nrow(valid)/nrow(UniversalBank1))*100
Prop_test <- (nrow(test)/nrow(UniversalBank1))*100

# Print Proportion
paste(Prop_train,"% In Training",Prop_valid,"% In Validation",Prop_test,"% In Test")

```

```{r 12, echo=TRUE}

# Setting Seed
set.seed(1)

# Removing Some Predictors
train <- train[,-c("ID","ZIP Code")]
valid <- valid[,-c("ID","ZIP Code")]
test <- test[,-c("ID","ZIP Code")]

# Target Variable As Factor
train$`Personal Loan` <- as.factor(train$`Personal Loan`) 
valid$`Personal Loan` <- as.factor(valid$`Personal Loan`) 
test$`Personal Loan` <- as.factor(test$`Personal Loan`) 

# Education As Factor
train$Education <- as.factor(train$Education) 
valid$Education <- as.factor(valid$Education) 
test$Education <- as.factor(test$Education) 

# Education One-Hot Encoding
Education_As_Dummy_Train <- model.matrix(~0+train$Education)
Education_As_Dummy_Valid <- model.matrix(~0+valid$Education)
Education_As_Dummy_Test <- model.matrix(~0+test$Education)

# Append to Training and Validation Sets
train <- cbind(train,Education_As_Dummy_Train)
train <- train[,-c("Education")]

valid <- cbind(valid,Education_As_Dummy_Valid)
valid <- valid[,-c("Education")]

test <- cbind(test,Education_As_Dummy_Test)
test <- test[,-c("Education")]

# Renaming Education
train = train %>% rename( Education_1 = `train$Education1` , Education_2 = `train$Education2`, Education_3 = `train$Education3`)
valid = valid %>% rename( Education_1 = `valid$Education1` , Education_2 = `valid$Education2`, Education_3 = `valid$Education3`)
test = test %>% rename( Education_1 = `test$Education1` , Education_2 = `test$Education2`, Education_3 = `test$Education3`)

# Preprocess for Data Normalization
library(caret)

train_norm <- train
validn_norm <- valid
test_norm <- test

train_norm_s <- train[,-c("Personal Loan")]

norm_values_2 <- preProcess(train_norm_s,method = c("center","scale"))

train_norm <- predict(norm_values_2,train)
valid_norm <- predict(norm_values_2,valid)
test_norm <- predict(norm_values_2,test)


```

<center>

> Confusion Matrix for Train VS Valid

```{r 13, echo=TRUE}

# Train VS Valid

# Setting Seed
set.seed(1)

# Computing Confusion Matrix with Best K
predictions_k_new <- knn(train=train_norm[,-c("Personal Loan")],test = valid_norm[,-c("Personal Loan")], cl = train_norm$`Personal Loan`, highest_K)

# As Factor Predictions
predictions_k_new <- as.factor(predictions_k_new)

# Relabel 0 and 1 to "Success" and "Fail
levels(predictions_k_new)<- c("Fail","Success")
levels(valid$`Personal Loan`) <- c("Fail","Success")

# Confusion Matrix
Confusion_Matrix_k_New <- confusionMatrix(data = predictions_k_new, reference = valid$`Personal Loan`)

#Plot the Confusion Matrix
draw_confusion_matrix(Confusion_Matrix_k_New)


```

</center>


<center>

> Confusion Matrix for Train VS Test

```{r 14, echo=TRUE}

# Train VS Test

# Setting Seed
set.seed(1)

# Computing Confusion Matrix with Best K
predictions_k_new2 <- knn(train=train_norm[,-c("Personal Loan")],test = test_norm[,-c("Personal Loan")], cl = train_norm$`Personal Loan`, highest_K)

# As Factor Predictions
predictions_k_new2 <- as.factor(predictions_k_new2)

# Relabel 0 and 1 to "Success" and "Fail
levels(predictions_k_new2)<- c("Fail","Success")
levels(test$`Personal Loan`) <- c("Fail","Success")

# Confusion Matrix
Confusion_Matrix_k_New2 <- confusionMatrix(data = predictions_k_new2, reference = test$`Personal Loan`)

#Plot the Confusion Matrix
draw_confusion_matrix(Confusion_Matrix_k_New2)

```

</center>


# <span style="color: #1c6155;">Exercise 3.</span>

## 8.1 Personal Loan Acceptance

### Partition the data into training (60%) and validation (40%) sets

```{r a1, echo=TRUE}

UniversalBank2 <- fread("DATA/UniversalBank.csv")

# Setting Seed
set.seed(1)

# Splitting Training and Validation 
sample2 <- sample(c(TRUE, FALSE), nrow(UniversalBank2), replace=TRUE, prob=c(0.6,0.4))
training_8  <- UniversalBank2[sample2, ]
validation_8   <- UniversalBank2[!sample2, ]

# Checking if proportions are right
training_8_prop <- (nrow(training_8)/nrow(UniversalBank2))*100
validation_8_prop <- (nrow(validation_8)/nrow(UniversalBank2))*100

paste(training_8_prop,"% In Training",validation_8_prop,"% In Validation")

```

### a) Pivot Table

<center>

```{r a2, echo=TRUE}

library(pivottabler)

# Duplicata of Training Data for Pivot Data
pivot_data <- training_8

# As Factor
pivot_data$Online <- factor(pivot_data$Online,levels = c(0,1),labels=c("Inactive Online","Active Online"))
pivot_data$CreditCard <- factor(pivot_data$CreditCard,levels = c(0,1),labels=c("No Credit Card","Credit Card"))
pivot_data$`Personal Loan` <- factor(pivot_data$`Personal Loan`,levels = c(0,1),labels=c("No Personal Loan","Personal Loan"))

# Pivot Table
pt <- PivotTable$new()
pt$addData(pivot_data) 
pt$addColumnDataGroups("CreditCard")
pt$addRowDataGroups("Personal Loan")
pt$addRowDataGroups("Online")
pt$defineCalculation(calculationName="Total", summariseExpression="n()")
pt$renderPivot()

```

</center>

### b) Probability Customer who owns a bank credit acrd and is actively using online banking services accept the loan offer?

> Using Bayes Theorem

$$\small P(Loan=1 | CC=1 \cap Online=1) =  \\ \small \dfrac{P(Loan=1 \cap CC=1 \cap Online=1)}{P(CC=1 \cap Online=1)} = \\ \small \dfrac{\dfrac{54}{3050}}{\dfrac{506+54}{3050}} =\dfrac{54}{560} = 9.642 \% $$

> Thus, there is 9.642% probability that this kind of customer would accept the loan offer.

### c) Pivot Table in 2 Versions

<center>

```{r a4, echo=TRUE}

library(pivottabler)

# Pivot Table 1
pt1 <- PivotTable$new()
pt1$addData(pivot_data) 
pt1$addColumnDataGroups("Online")
pt1$addRowDataGroups("Personal Loan")
pt1$defineCalculation(calculationName="Total", summariseExpression="n()")
pt1$renderPivot()

# Pivot Table 1
pt2 <- PivotTable$new()
pt2$addData(pivot_data) 
pt2$addColumnDataGroups("CreditCard")
pt2$addRowDataGroups("Personal Loan")
pt2$defineCalculation(calculationName="Total", summariseExpression="n()")
pt2$renderPivot()

```

</center>

### d) Compute the following quantities

#### i. 

$$\small P (CC=1 | Loan=1) = \\ \small \dfrac{P (CC=1 \cap Loan=1)}{P (Loan=1)} = \\ \small \dfrac{95}{297} = 31.99 \%  $$

#### ii.

$$\small P (Online=1 | Loan=1) = \\ \small \dfrac{P (Online=1 \cap Loan=1)}{P (Loan=1)} = \\\small  \dfrac{188}{297} = 63.30 \%$$

#### iii.

$$\small P (Loan=1) =  \dfrac{297}{3050} = 9.74 \%$$

#### iv.

$$\small P (CC=1 | Loan=0) = \\\small \dfrac{P (CC=1 \cap Loan=0)}{P (Loan=0)} = \\\small \dfrac{827}{2753} = 30.04 \%$$

#### v.

$$\small P (Online=1 | Loan=0) = \\ \small \dfrac{P (Online=1 \cap Loan=0)}{P (Loan=0)} = \\ \small \dfrac{1626}{2753} = 59.06 \%$$

#### vi.

$$\small P (Loan=0) = \dfrac{2753}{3050} =  90.26\%$$



### e) Compute naive Bayes Probability 

$$\small P(Loan=1|CC=1,Online=1)$$
Using the naive Bayes Probability give us the following computation:

$$\small P(Loan=1|CC=1,Online=1) = \\ \small P(Loan=1)*P(Loan=1|CC=1)*P(Loan=1|Online=1)=\\ \small  9.74\% *31.99\% *63.30 \% = 1.97\% $$ 


### f) Accurate Estimate





### g) Run Model and Comparisons

$$P(Loan=1|CC=1,Online=1)$$

```{r a5, echo=TRUE}

library(naivebayes)

# As factor for Loan
training_8$Online <- factor(training_8$Online,levels = c(0,1),labels=c("Inactive Online","Active Online"))
training_8$CreditCard <- factor(training_8$CreditCard,levels = c(0,1),labels=c("No Credit Card","Credit Card"))
training_8$`Personal Loan` <- factor(training_8$`Personal Loan`,levels = c(0,1),labels=c("No Personal Loan","Personal Loan"))

Naivebayes <-  naive_bayes(training_8$`Personal Loan` ~ training_8$CreditCard + training_8$Online, data=training_8)

summary(Naivebayes)

Naivebayes

```

$$\small P(Loan=1|CC=1,Online=1) =  \small 0.09737705*0.3198653*0.6329966 \\ \small= 0.01971629 = 1.97\% $$ 


# <span style="color: #1c6155;">References</span>

[Github Repo for this Homework 2](https://github.com/LiamPhan17/DATA_MINING_HW2)

[Data Mining for Business Analytics: Concepts, Techniques, and Applications in R](https://www.wiley.com/en-us/Data+Mining+for+Business+Analytics:+Concepts,+Techniques,+and+Applications+in+R-p-9781118879368)

[How to Split Data into Training & Test Sets in R (3 Methods)](https://www.statology.org/train-test-split-r/)